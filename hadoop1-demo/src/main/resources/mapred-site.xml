<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<property>
		<name>mapred.job.tracker</name>
		<value>node102.vipcloud:9001</value>
		<description>
			The host and port that the MapReduce job tracker runs
			at.
			If "local", then jobs are run in-process as a single map
			and reduce
			task.
		</description>
	</property>

	<property>
		<name>mapred.local.dir</name>
		<value>${hadoop.tmp.dir}/data/mapred/local,${hadoop.tmp.dir}/data2/mapred/local</value>
		<description>
			The local directory where MapReduce stores intermediate
			data files. May
			be a comma-separated list of
			directories on different
			devices in order
			to spread disk i/o.
			Directories that do not exist are
			ignored.
		</description>
	</property>

	<property>
		<name>mapred.temp.dir</name>
		<value>${hadoop.tmp.dir}/data/mapred/temp,${hadoop.tmp.dir}/data2/mapred/temp</value>
		<description>A shared directory for temporary files.
		</description>
	</property>

	<property>
		<name>mapred.system.dir</name>
		<value>${hadoop.tmp.dir}/mapred/system</value>
		<description>The directory where MapReduce stores control files.
		</description>
	</property>

	<property>
		<name>mapred.local.dir.minspacestart</name>
		<value>0</value>
		<description>
			If the space in mapred.local.dir drops under this,do not
			ask for more tasks.Value in bytes.
		</description>
	</property>

	<property>
		<name>mapred.task.tracker.report.address</name>
		<value>127.0.0.1:50061</value>
		<description>The interface and port that task tracker server listens
			on.
			Since it is only connected to by the tasks, it uses the local
			interface.
			EXPERT ONLY. Should only be changed if your host does not
			have the
			loopback
			interface.
		</description>
	</property>
	<property>
		<name>mapred.local.dir.minspacekill</name>
		<value>0</value>
		<description>
			If the space in mapred.local.dir drops under this,do not
			ask more tasks until all the current ones have finished and
			cleaned
			up. Also, to save the rest of the tasks we have running,
			kill one of
			them, to clean up some space. Start with the reduce tasks,
			then go
			with the ones that have finished the least.
			Value in bytes.
		</description>
	</property>
	<property>
		<name>mapred.tasktracker.map.tasks.maximum</name>
		<value>10</value>
		<description>The maximum number of map tasks that will be run
			simultaneously by a task tracker.
		</description>
	</property>

	<property>
		<name>total.task.max.use.proc.num</name>
		<value>10</value>
		<description>cqvip custom property ,control tasktracker can used max
			cpu num</description>
	</property>

	<property>
		<name>mapred.tasktracker.reduce.tasks.maximum</name>
		<value>10</value>
		<description>The maximum number of reduce tasks that will be run
			simultaneously by a task tracker.
		</description>
	</property>

	 

	<property>
		<name>mapred.reduce.slowstart.completed.maps</name>
		<value>0.3</value>
	</property>

	<property>
		<name>mapred.compress.map.output</name>
		<value>true</value>
	</property>

	<property>
		<name>mapred.map.output.compression.codec</name>
		<value>com.hadoop.compression.lzo.LzoCodec</value>
	</property>

	<property>
		<name>mapred.user.jobconf.limit</name>
		<value>5242880</value>
		<description>
			The maximum allowed size of the user jobconf. The
			default
			is set to 5 MB
		</description>
	</property>

	<property>
		<name>mapred.job.reuse.jvm.num.tasks</name>
		<value>100</value>
		<description>
			How many tasks to run per jvm. If set to -1, there is no
			limit.
		</description>
	</property>

	<property>
		<name>mapred.userlog.retain.hours</name>
		<value>96</value>
		<description>The maximum time, in hours, for which the user-logs are
			to be retained after the job completion.
		</description>
	</property>

	<!-- i/o properties -->
	<property>
		<name>io.sort.factor</name>
		<value>100</value>
		<description>The number of streams to merge at once while sorting
			files. This determines the number of open file handles.
			Default is 10
		</description>
	</property>

	<property>
		<name>io.sort.mb</name>
		<value>1024</value>
		<description>The total amount of buffer memory to use while sorting
			files, in megabytes. By default, gives each merge stream 1MB, which
			should minimize seeks.
			Default is 100M
		</description>
	</property>

	<property>
		<name>io.sort.record.percent</name>
		<value>0.05</value>
		<description>The percentage of io.sort.mb dedicated to tracking record
			boundaries. Let this value be r, io.sort.mb be x. The maximum number
			of records collected before the collection thread must block is equal
			to (r * x) / 4
		</description>
	</property>

	<property>
		<name>io.sort.spill.percent</name>
		<value>0.80</value>
		<description>The soft limit in either the buffer or record collection
			buffers. Once reached, a thread will begin to spill the contents to
			disk
			in the background. Note that this does not imply any chunking of
			data
			to
			the spill. A value less than 0.5 is not recommended.
		</description>
	</property>

	<property>
		<name>io.map.index.skip</name>
		<value>0</value>
		<description>Number of index entries to skip between each entry.
			Zero
			by default. Setting this to values larger than zero can
			facilitate
			opening large map files using less memory.
		</description>
	</property>

	<property>
		<name>mapred.job.tracker.handler.count</name>
		<value>20</value>
		<description>
			The number of server threads for the JobTracker. This
			should be roughly
			4% of the number of tasktracker nodes.
		</description>
	</property>


	<!-- TaskTracker DistributedCache configuration -->
	<property>
		<name>local.cache.size</name>
		<value>10737418240</value>
		<description>
			The number of bytes to allocate in each local TaskTracker
			directory for holding Distributed Cache data.
			Default is
			1G(10737418240)
		</description>
	</property>

	<property>
		<name>mapreduce.tasktracker.cache.local.numberdirectories</name>
		<value>10000</value>
		<description>
			The maximum number of subdirectories that should be
			created in any particular distributed cache store. After this many
			directories have been created,cache items will be expunged regardless
			of whether the total size threshold has been exceeded.
		</description>
	</property>
	<!-- End of TaskTracker DistributedCache configuration -->

	<property>
		<name>mapreduce.tasktracker.outofband.heartbeat</name>
		<value>true</value>
		<description>Expert: Set this to true to let the tasktracker send an
			out-of-band heartbeat on task-completion for better latency.
		</description>
	</property>

	<property>
		<name>mapred.map.max.attempts</name>
		<value>5</value>
		<description>Expert: The maximum number of attempts per map task.
			In
			other words, framework will try to execute a map task these many
			number of times before giving up on it.
		</description>
	</property>

	<property>
		<name>mapred.reduce.max.attempts</name>
		<value>5</value>
		<description>Expert: The maximum number of attempts per reduce task.
			In other words, framework will try to execute a reduce task these
			many number
			of times before giving up on it.
		</description>
	</property>

	<property>
		<name>mapred.reduce.parallel.copies</name>
		<value>30</value>
		<description>The default number of parallel transfers run by reduce
			during the copy(shuffle) phase.
		</description>
	</property>

	<property>
		<name>tasktracker.http.threads</name>
		<value>50</value>
		<description>The number of worker threads that for the http server.
			This is
			used for map output fetching
		</description>
	</property>

	<property>
		<name>mapreduce.reduce.shuffle.maxfetchfailures</name>
		<value>20</value>
		<description>The maximum number of times a reducer tries to
			fetch a map
			output before it reports it.
		</description>
	</property>

	<property>
		<name>mapreduce.reduce.shuffle.connect.timeout</name>
		<value>180000</value>
		<description>Expert: The maximum amount of time (in milli seconds) a
			reduce
			task spends in trying to connect to a tasktracker for getting
			map output.
		</description>
	</property>

	<property>
		<name>mapreduce.reduce.shuffle.read.timeout</name>
		<value>180000</value>
		<description>Expert: The maximum amount of time (in milli seconds) a
			reduce
			task waits for map output data to be available for reading
			after
			obtaining
			connection.
		</description>
	</property>

	<property>
		<name>mapred.task.timeout</name>
		<value>600000</value>
		<description>The number of milliseconds before a task will be
			terminated if it neither reads an input, writes an output, nor
			updates its status string.
		</description>
	</property>

	<property>
		<name>mapred.inmem.merge.threshold</name>
		<value>1000</value>
		<description>The threshold, in terms of the number of files
			for the
			in-memory merge process. When we accumulate threshold number of
			files
			we initiate the in-memory merge and spill to disk. A value of 0 or
			less
			than
			0 indicates we want to DON'T have any threshold and instead
			depend
			only on
			the ramfs's memory consumption to trigger the merge.
		</description>
	</property>

	<property>
		<name>mapred.job.shuffle.merge.percent</name>
		<value>0.66</value>
		<description>The usage threshold at which an in-memory merge will be
			initiated, expressed as a percentage of the total memory allocated to
			storing in-memory map outputs, as defined by
			mapred.job.shuffle.input.buffer.percent.
		</description>
	</property>

	<property>
		<name>mapred.job.shuffle.input.buffer.percent</name>
		<value>0.70</value>
		<description>The percentage of memory to be allocated from the maximum
			heap
			size to storing map outputs during the shuffle.
		</description>
	</property>

	<property>
		<name>mapred.job.reduce.input.buffer.percent</name>
		<value>0.0</value>
		<description>The percentage of memory- relative to the maximum heap
			size- to
			retain map outputs during the reduce. When the shuffle is
			concluded, any
			remaining map outputs in memory must consume less than
			this threshold
			before
			the reduce can begin.
		</description>
	</property>

	<property>
		<name>mapred.map.tasks.speculative.execution</name>
		<value>false</value>
		<description>If true, then multiple instances of some map tasks
			may be
			executed in parallel.
		</description>
	</property>

	<property>
		<name>mapred.reduce.tasks.speculative.execution</name>
		<value>false</value>
		<description>If true, then multiple instances of some reduce tasks
			may
			be executed in parallel.
		</description>
	</property>

	<!-- JobTracker -->
	<property>
		<name>mapred.jobtracker.taskScheduler</name>
		<value>org.apache.hadoop.mapred.FairScheduler</value>
		<description>
			The class responsible for scheduling the tasks.
		</description>
	</property>

	<property>
		<name>mapreduce.jobtracker.split.metainfo.maxsize</name>
		<value>10000000</value>
		<description>The maximum permissible size of the split metainfo file.
			The JobTracker won't attempt to read split metainfo files bigger than
			the configured value.
			No limits if set to -1.
			Default is 10M
		</description>
	</property>

	<property>
		<name>mapred.jobtracker.taskScheduler.maxRunningTasksPerJob</name>
		<value></value>
		<description>The maximum number of running tasks for a job before
			it
			gets preempted. No limits if undefined.
		</description>
	</property>

	<property>
		<name>mapred.jobtracker.completeuserjobs.maximum</name>
		<value>100</value>
		<description>
			The maximum number of complete jobs per user to keep
			around
			before delegating them to the job history.
		</description>
	</property>

	<property>
		<name>mapred.job.tracker.retiredjobs.cache.size</name>
		<value>1000</value>
		<description>The number of retired job status to keep in the cache.
		</description>
	</property>

	<property>
		<name>mapred.jobtracker.maxtasks.per.job</name>
		<value>-1</value>
		<description>The maximum number of tasks for a single job.
			A value of
			-1 indicates that there is no maximum.
		</description>
	</property>

	<property>
		<name>mapred.submit.replication</name>
		<value>10</value>
		<description>The replication level for submitted job files. This
			should be around the square root of the number of nodes.
		</description>
	</property>

	<property>
		<name>keep.failed.task.files</name>
		<value>false</value>
		<description>Should the files for failed tasks be kept. This should
			only be
			used on jobs that are failing, because the storage is never
			reclaimed. It also prevents the map outputs from being erased
			from the
			reduce directory as they are consumed.
		</description>
	</property>

	<property>
		<name>mapred.hosts</name>
		<value></value>
		<description>Names a file that contains the list of nodes that may
			connect to the jobtracker. If the value is empty, all hosts are
			permitted.
		</description>
	</property>

	<property>
		<name>mapred.hosts.exclude</name>
		<value></value>
		<description>Names a file that contains the list of hosts that
			should
			be excluded by the jobtracker. If the value is empty, no
			hosts are
			excluded.
		</description>
	</property>

	<property>
		<name>mapred.max.tracker.failures</name>
		<value>4</value>
		<description>The number of task-failures on a tasktracker of a given
			job after which new tasks of that job aren't assigned to it.
		</description>
	</property>


	<property>
		<name>mapred.jobtracker.restart.recover</name>
		<value>false</value>
		<description>"true" to enable (job) recovery upon restart,
			"false" to
			start afresh
		</description>
	</property>

	<property>
		<name>mapred.job.tracker.persist.jobstatus.active</name>
		<value>false</value>
		<description>Indicates if persistency of job status information is
			active or not.
		</description>
	</property>

	<property>
		<name>mapred.job.tracker.persist.jobstatus.hours</name>
		<value>0</value>
		<description>The number of hours job status information is persisted
			in DFS.
			The job status information will be available after it drops of
			the
			memory
			queue and between jobtracker restarts. With a zero value the
			job status
			information is not persisted at all in DFS.
		</description>
	</property>

	<property>
		<name>mapred.job.tracker.persist.jobstatus.dir</name>
		<value>/jobtracker/jobsInfo</value>
		<description>The directory where the job status information is
			persisted
			in a file system to be available after it drops of the
			memory queue and
			between jobtracker restarts.
		</description>
	</property>
<property>
	<name>mapred.job.map.memory.mb</name>
	<value>2048</value>
</property>
<property>
        <name>mapred.job.map.memory.mb</name>
        <value>2048</value>
</property>

<property> 
        <name>mapreduce.jobtracker.kerberos.principal</name> 
        <value>vipcloud/_HOST@CQVIP.COM</value> 
</property> 
<property> 
        <name>mapreduce.jobtracker.kerberos.https.principal</name> 
        <value>HTTP/_HOST@CQVIP.COM</value>
</property> 
<property> 
        <name>mapreduce.jobtracker.keytab.file</name> 
        <value>/usr/local/vipcloud/hadoop/conf/vipcloud.keytab</value> 
        <!-- path to the MapReduce keytab --> 
</property> 

<!-- TaskTracker security configs --> 
<property> 
        <name>mapreduce.tasktracker.kerberos.principal</name> 
        <value>vipcloud/_HOST@CQVIP.COM</value> 
</property> 
<property> 
        <name>mapreduce.tasktracker.kerberos.https.principal</name> 
        <value>HTTP/_HOST@CQVIP.COM</value> 
</property> 
<property> 
        <name>mapreduce.tasktracker.keytab.file</name> 
        <value>/usr/local/vipcloud/hadoop/conf/vipcloud.keytab</value> 
        <!-- path to the MapReduce keytab --> 
</property> 

</configuration>
